{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94876bcf-b2fc-4628-a51d-397c10154be9",
   "metadata": {},
   "source": [
    "## Stemming:\n",
    "Stemming is the process of reducing a word to its base or root form, usually by removing suffixes. It's a form of text normalization that helps treat related words (like \"connect\", \"connected\", \"connection\") as the same root term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ed9d6-eacc-47c7-a210-4a7f53828a06",
   "metadata": {},
   "source": [
    "## Stemming Type:\n",
    "<ul>\n",
    "  <li><strong>Rule-Based (Porter Stemmer):</strong> Uses a set of rules to remove common suffixes.</li>\n",
    "  <li><strong>Snowball Stemmer:</strong> Improved version of Porter stemmer with support for multiple languages.</li>\n",
    "  <li><strong>Lancaster Stemmer:</strong> More aggressive and faster than Porter. Can over-stem.</li>\n",
    "  <li><strong>Regex-Based Stemming:</strong> Uses custom regex rules to define stems. Very flexible but less standardized.</li>\n",
    "  <li><strong>Lemmatization (not exactly stemming):</strong> Uses vocabulary + grammar to find the correct base form. More accurate.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9eaceb9-0086-4db6-bb43-ea65dcf1af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f21c561-793c-4d59-849e-0a359ea64b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing is fun.', \"Let's explore tokenization with NLTK!\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer,WordPunctTokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load pretrained tokenizer for English\n",
    "tokenizer1 = PunktSentenceTokenizer()\n",
    "tokenizer2 = WordPunctTokenizer()\n",
    "text = \"Natural Language Processing is fun. Let's explore tokenization with NLTK!\"\n",
    "sentences = tokenizer1.tokenize(text)\n",
    "\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ad7f767-15f0-482f-b71c-0879984683a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['The', 'children', 'are', 'playing', ',', 'studied', ',', 'and', 'flying', 'in', 'different', 'directions', '.']\n"
     ]
    }
   ],
   "source": [
    "text2 = \"The children are playing, studied, and flying in different directions.\"\n",
    "tokens = tokenizer2.tokenize(text2)\n",
    "print(\"Original Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2270a3f-fecd-4f37-8848-5099c9a3efd5",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa208113-b221-40f4-bcef-20e639c5735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dcc4601-a993-4647-bd24-da0196df3c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"Congratulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff5483-4abf-4993-80b5-94e1f9ef955f",
   "metadata": {},
   "source": [
    "## Snowball Stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0377b6d2-7337-4d16-bee8-2d1cf62ae075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Specify the language (e.g., English)\n",
    "snowstemming = SnowballStemmer(\"english\")\n",
    "\n",
    "# Example usage\n",
    "word = \"running\"\n",
    "print(snowstemming.stem(word))  # Output: run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8a2ae-5124-42d5-8ca2-7317389e22c5",
   "metadata": {},
   "source": [
    "## Lancaster Stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e621d292-9046-4910-8083-4ac030317540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['running', 'flies', 'fairly', 'maximum', 'studies']\n",
      "Lancaster Stems: ['run', 'fli', 'fair', 'maxim', 'study']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Create stemmer instance\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "# Example words\n",
    "words = [\"running\", \"flies\", \"fairly\", \"maximum\", \"studies\"]\n",
    "\n",
    "# Apply stemming\n",
    "stems = [lancaster.stem(word) for word in words]\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Lancaster Stems:\", stems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a674f-63e8-4f65-ae7c-1da19677e871",
   "metadata": {},
   "source": [
    "## Regex-Based Stemming: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "701de0cc-ac8e-4400-bcc2-a3ba1b94b730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words: ['running', 'played', 'flies', 'studies', 'happier']\n",
      "Regex Stems: ['runn', 'play', 'flie', 'studie', 'happier']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Define custom regex patterns for stemming\n",
    "regex_stemmer = RegexpStemmer('ing$|ed$|s$')\n",
    "\n",
    "# Example words to stem\n",
    "words = [\"running\", \"played\", \"flies\", \"studies\", \"happier\"]\n",
    "\n",
    "# Apply stemming\n",
    "stems = [regex_stemmer.stem(word) for word in words]\n",
    "\n",
    "print(\"Original Words:\", words)\n",
    "print(\"Regex Stems:\", stems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7477b775-5d6d-4031-beda-6692fdfee911",
   "metadata": {},
   "source": [
    "## Lemmatization (not exactly stemming):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28b1d426-bdec-4b63-80bc-19e9c0581e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['The', 'children', 'are', 'playing', ',', 'studied', ',', 'and', 'flying', 'in', 'different', 'directions', '.']\n",
      "Lemmatized Words: ['The', 'children', 'be', 'play', ',', 'study', ',', 'and', 'fly', 'in', 'different', 'directions', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Example text\n",
    "text = \"The children are playing and they have been running for hours.\"\n",
    "\n",
    "# Lemmatize each word (using 'v' for verb lemmatization)\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in tokens]\n",
    "\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Lemmatized Words:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5408ce-504e-4252-950c-70aabf5f0b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
