{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad999f9e-6081-4b51-9376-eb45a4060b08",
   "metadata": {},
   "source": [
    "### Stopwords:\n",
    "Stopwords are common words (such as \"the\", \"is\", \"in\", \"and\", etc.) that are usually removed during text preprocessing because they don't carry much meaningful information for tasks like text classification, sentiment analysis, or information retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a60009-2281-4df2-972a-45d8e353bc14",
   "metadata": {},
   "source": [
    "### Common Stopwords:\n",
    "<ul>\n",
    "  <li><strong>Articles:</strong> \"a\", \"an\", \"the\"</li>\n",
    "  <li><strong>Prepositions:</strong> \"in\", \"on\", \"at\"</li>\n",
    "  <li><strong>Conjunctions:</strong> \"and\", \"but\", \"or\"</li>\n",
    "  <li><strong>Pronouns:</strong> \"he\", \"she\", \"it\", \"they\"</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e3d4cc-31ca-4d09-a804-391dcfde07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"Good day, everyone!Today, I'd like to talk to you about an important concept in Natural Language Processing—stopwords.In the realm of text processing and data analysis, stopwords are commonly encountered words that don't carrymuch meaningful information, and therefore, are oftenremoved from texts to focus on more significant words.Let’s break this down a bit further. Consider a typical sentence like this:‘This is a simple example to demonstrate stopwords removal in NLP.’Now, if we look at the words in this sentence, we can identify certain words that don’t add much value in understanding the context or meaning.For example, the words ‘this’, ‘is’, ‘a’, ‘to’, and ‘in’ are what we call stopwords. They are grammatical words that help form the structure of a sentence but don’t carry specific meaning on their own.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0970115b-e28e-45e7-b68e-5f81445d7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1261a657-941c-4ecf-8163-2f8940174213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec10378a-9313-4000-b6bc-0ea96c810601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec5023b9-e576-4f9e-bbf8-f3a3f327e3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00a238d-4870-4b70-b90d-517b11de1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547d8b2c-4ba2-497e-9e4d-ea429df7ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e9b22aa-c517-4dc3-af8e-fea9ca565017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentences=nltk.sent_tokenize(paragraph)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "297d1abc-ef1d-4718-8fa7-51ed47aa44be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there!', 'How are you doing today?', 'This is a test for sentence tokenization using NLTK.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer,WordPunctTokenizer\n",
    "\n",
    "tokenizer1 = PunktSentenceTokenizer()\n",
    "tokenizer2 = WordPunctTokenizer()\n",
    "\n",
    "# Apply sentence tokenization\n",
    "sentences = tokenizer1.tokenize(paragraph)\n",
    "\n",
    "# Print the tokenized sentences\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b807145e-b0d1-48a8-aa14-5b1679087fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7498ba03-e06e-461a-b47a-22885b9ee90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply Stopwords and filter and then apply stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = tokenizer1.tokenize(sentences[i])  # tokenize into words\n",
    "    filtered = [stemmer.stem(word) for word in words if word.lower() not in set(stopwords.words('english')) and word.isalnum()]\n",
    "    sentences[i] = ' '.join(filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a18df1e5-c42b-4d3c-bb96-ed0d9b784e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518682f-0f87-4f03-b6bd-32ab77f2d88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cfd5354-ff8a-4248-be33-05c347307f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: nltk 3.9.1\n",
      "Uninstalling nltk-3.9.1:\n",
      "  Successfully uninstalled nltk-3.9.1\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\roger\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\roger\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\roger\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roger\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\roger\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall nltk -y\n",
    "!pip install nltk --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a045de47-a95e-4e10-87b6-b0a7c5f410fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\roger/nltk_data', 'C:\\\\Users\\\\roger\\\\anaconda3\\\\nltk_data', 'C:\\\\Users\\\\roger\\\\anaconda3\\\\share\\\\nltk_data', 'C:\\\\Users\\\\roger\\\\anaconda3\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\roger\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29427911-c746-4cbe-a4cf-6ad4e6b33ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ea9f4-0b3a-48a5-bae7-0fc5459244d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1eab08-c171-4885-b8cd-423bc943dd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
